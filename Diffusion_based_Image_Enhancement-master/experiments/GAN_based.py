import torch.nn as nn
from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR, SequentialLR
import torch
from GANDataset import ImageDataset
from torch.utils.data import DataLoader
from tqdm import tqdm
import piq


class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=4, stride=2, padding=1),  # Downsample
            nn.ReLU(inplace=True),
            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True),
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # Upsample
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1),
            nn.Tanh(),  # Output in the range [-1, 1]
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x


# Discriminator Network (PatchGAN)
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=4, stride=2, padding=1),  # Downsample
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 1, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid(),  # Output a probability between 0 and 1
        )

    def forward(self, x):
        return self.model(x)

if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    cuda = True if torch.cuda.is_available() else False

    # Loss function
    criterion_GAN = nn.BCELoss()  # Binary Cross-Entropy Loss for GAN
    criterion_L1 = nn.L1Loss()  # L1 Loss for image similarity (optional, for reconstruction)

    # Initialize generator and discriminator
    generator = Generator().to(device)
    discriminator = Discriminator().to(device)

    train_ds = ImageDataset('train', device)
    valid_ds = ImageDataset('valid', device)
    dl_t = DataLoader(train_ds, batch_size=16, shuffle=True, drop_last=True)
    dl_v = DataLoader(valid_ds, batch_size=1, shuffle=False, drop_last=True)

    # Optimizers
    optimizer_G = torch.optim.Adam(generator.parameters(), lr=1e-3, betas=(0.5, 0.999))
    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=1e-3, betas=(0.5, 0.999))

    batches_per_epoch = len(dl_t)
    total_steps = 100 * batches_per_epoch
    warmup_steps = 2000
    def warmup_lambda(step):
        return min(1.0, step / warmup_steps)


    warmup_scheduler_G = LambdaLR(optimizer_G, lr_lambda=warmup_lambda)

    cosine_scheduler_G = CosineAnnealingLR(
        optimizer_G,
        T_max=(total_steps - warmup_steps),
        eta_min=5e-5
    )

    scheduler_G = SequentialLR(
        optimizer_G,
        schedulers=[warmup_scheduler_G, cosine_scheduler_G],
        milestones=[warmup_steps]
    )

    warmup_scheduler_D = LambdaLR(optimizer_D, lr_lambda=warmup_lambda)

    cosine_scheduler_D = CosineAnnealingLR(
        optimizer_D,
        T_max=(total_steps - warmup_steps),
        eta_min=5e-5
    )

    scheduler_D = SequentialLR(
        optimizer_D,
        schedulers=[warmup_scheduler_D, cosine_scheduler_D],
        milestones=[warmup_steps]
    )

    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor

    max_psnr = 0
    for epoch in range(100):
        # training
        t_d_loss_real, t_d_loss_fake, t_g_loss_total = 0, 0, 0
        for DSImg, truth in tqdm(dl_t):
            DSImg = DSImg.to(device)
            truth = truth.to(device)
            # Train Discriminator
            optimizer_D.zero_grad()

            # Real images
            outputs = discriminator(truth)

            real_labels = torch.ones_like(outputs).to(device)
            fake_labels = torch.zeros_like(outputs).to(device)

            d_loss_real = criterion_GAN(outputs, real_labels)
            t_d_loss_real += d_loss_real.item()
            d_loss_real.backward()

            # Fake images generated by the generator
            generated_images = (generator(DSImg) + 1) / 2
            outputs = discriminator(generated_images.detach())
            d_loss_fake = criterion_GAN(outputs, fake_labels)
            t_d_loss_fake += d_loss_fake.item()
            d_loss_fake.backward()

            optimizer_D.step()
            scheduler_D.step()

            # Train Generator
            optimizer_G.zero_grad()

            # We want the generator to fool the discriminator
            outputs = discriminator(generated_images)
            g_loss = criterion_GAN(outputs, real_labels)  # Generator tries to make fake images look real

            # Optionally add L1 loss for better image quality (optional)
            l1_loss = criterion_L1(generated_images, truth)

            g_loss_total = g_loss + l1_loss
            t_g_loss_total += g_loss.item()
            g_loss_total.backward()

            optimizer_G.step()
            scheduler_G.step()

        print(f"Epoch [{epoch + 1}/{100}], D Loss: {(t_d_loss_real + t_d_loss_fake) / len(dl_t):.4f}, G Loss: {t_g_loss_total / len(dl_t):.4f}, lr: {scheduler_G.get_last_lr()[0]:.6f}")

        # validation

        with torch.no_grad():
            discriminator.eval()
            generator.eval()
            psnr_total = 0
            ssim_total = 0
            gmsd_total = 0
            for DSImg, truth in tqdm(dl_v):
                DSImg = DSImg.to(device)
                truth = truth.to(device)
                generated_images = (generator(DSImg) + 1) / 2

                psnr_score = piq.psnr(generated_images, truth)
                psnr_total += psnr_score.item()

                ssim_score = piq.ssim(generated_images, truth)
                ssim_total += ssim_score.item()

                gmsd_score = piq.gmsd(generated_images, truth)
                gmsd_total += gmsd_score.item()
            print(f"Validation--- PSNR: {psnr_total / len(dl_v):.4f}, SSIM: {ssim_total / len(dl_v):.4f}, GMSD: {gmsd_total / len(dl_v):.4f}")
            if psnr_total / len(dl_v) > max_psnr:
                max_psnr = psnr_total / len(dl_v)
                torch.save(generator.state_dict(), f"GAN.pth")
                print("********Parameter Saved********")
            discriminator.train()
            generator.train()
